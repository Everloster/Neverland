{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抱抱脸的模型都存在本地什么位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 设置 Hugging Face 镜像\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "# 使用清华镜像\n",
    "#os.environ['HF_ENDPOINT'] = 'https://mirrors.tuna.tsinghua.edu.cn/hugging-face-models'\n",
    "from huggingface_hub import snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "# 下载模型并显示进度\n",
    "model_path = snapshot_download(\n",
    "    repo_id=\"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    local_dir_use_symlinks=False,  # Windows 系统建议设置为 False\n",
    "    tqdm_class=tqdm  # 添加进度条\n",
    ")\n",
    "print(f\"模型保存路径: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import scan_cache_dir, HfApi\n",
    "\n",
    "cache_info = scan_cache_dir()\n",
    "api = HfApi()\n",
    "\n",
    "# 打印所有缓存的模型\n",
    "for repo in cache_info.repos:\n",
    "    print(f\"模型名称: {repo.repo_id}\")\n",
    "    print(f\"本地路径: {repo.repo_path}\")\n",
    "    try:\n",
    "        # 检查模型在 Hub 上的状态\n",
    "        api.repo_info(repo_id=repo.repo_id)\n",
    "        print(f\"模型状态: 可访问\")\n",
    "    except Exception as e:\n",
    "        print(f\"模型状态: 不可访问或需要认证\")\n",
    "    print(f\"占用空间: {repo.size_on_disk / 1024 / 1024:.2f} MB\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集缓存目录: C:\\Users\\jabel/.cache/huggingface/datasets\n",
      "\n",
      "本地数据集信息:\n",
      "\n",
      "==================================================\n",
      "数据集: openai/gsm8k\n",
      "配置: main\n",
      "路径: C:\\Users\\jabel\\.cache\\huggingface\\datasets\\openai___gsm8k\\main\\0.0.0\\e53f048856ff4f594e959d75785d2c2d37b678ee\n",
      "大小: 8.71 MB\n",
      "\n",
      "描述: ...\n",
      "引用: ...\n",
      "\n",
      "数据样例(前10条):\n",
      "\n",
      "--- 数据 1 ---\n",
      "question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "answer: Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 2 ---\n",
      "question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "answer: Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\n",
      "Working 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\n",
      "#### 10\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 3 ---\n",
      "question: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "answer: In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\n",
      "Betty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\n",
      "This means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\n",
      "#### 5\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 4 ---\n",
      "question: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "answer: Maila read 12 x 2 = <<12*2=24>>24 pages today.\n",
      "So she was able to read a total of 12 + 24 = <<12+24=36>>36 pages since yesterday.\n",
      "There are 120 - 36 = <<120-36=84>>84 pages left to be read.\n",
      "Since she wants to read half of the remaining pages tomorrow, then she should read 84/2 = <<84/2=42>>42 pages.\n",
      "#### 42\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 5 ---\n",
      "question: James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "answer: He writes each friend 3*2=<<3*2=6>>6 pages a week\n",
      "So he writes 6*2=<<6*2=12>>12 pages every week\n",
      "That means he writes 12*52=<<12*52=624>>624 pages a year\n",
      "#### 624\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 6 ---\n",
      "question: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "answer: There are 80/100 * 10 = <<80/100*10=8>>8 more purple flowers than yellow flowers.\n",
      "So in Mark's garden, there are 10 + 8 = <<10+8=18>>18 purple flowers.\n",
      "Purple and yellow flowers sum up to 10 + 18 = <<10+18=28>>28 flowers.\n",
      "That means in Mark's garden there are 25/100 * 28 = <<25/100*28=7>>7 green flowers.\n",
      "So in total Mark has 28 + 7 = <<28+7=35>>35 plants in his garden.\n",
      "#### 35\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 7 ---\n",
      "question: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "answer: He eats 32 from the largest pizzas because 2 x 16 = <<2*16=32>>32\n",
      "He eats 16 from the small pizza because 2 x 8 = <<2*8=16>>16\n",
      "He eats 48 pieces because 32 + 16 = <<32+16=48>>48\n",
      "#### 48\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 8 ---\n",
      "question: Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\n",
      "answer: To the initial 2 pounds of jelly beans, he added enough brownies to cause the weight to triple, bringing the weight to 2*3=<<2*3=6>>6 pounds.\n",
      "Next, he added another 2 pounds of jelly beans, bringing the weight to 6+2=<<6+2=8>>8 pounds.\n",
      "And finally, he added enough gummy worms to double the weight once again, to a final weight of 8*2=<<8*2=16>>16 pounds.\n",
      "#### 16\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 9 ---\n",
      "question: Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "answer: Let S be the amount Alexis paid for the shoes.\n",
      "She spent S + 30 + 46 + 38 + 11 + 18 = S + <<+30+46+38+11+18=143>>143.\n",
      "She used all but $16 of her budget, so S + 143 = 200 - 16 = 184.\n",
      "Thus, Alexis paid S = 184 - 143 = $<<184-143=41>>41 for the shoes.\n",
      "#### 41\n",
      "----------------------------------------\n",
      "\n",
      "--- 数据 10 ---\n",
      "question: Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "answer: She works 8 hours a day for $18 per hour so she makes 8*18 = $<<8*18=144.00>>144.00 per 8-hour shift\n",
      "She works 10 hours a day and anything over 8 hours is eligible for overtime, so she gets 10-8 = <<10-8=2>>2 hours of overtime\n",
      "Overtime is calculated as time and a half so and she makes $18/hour so her overtime pay is 18*.5 = $<<18*.5=9.00>>9.00\n",
      "Her overtime pay is 18+9 = $<<18+9=27.00>>27.00\n",
      "Her base pay is $144.00 per 8-hour shift and she works 5 days and makes 5 * $144 = $<<144*5=720.00>>720.00\n",
      "Her overtime pay is $27.00 per hour and she works 2 hours of overtime per day and makes 27*2 = $<<27*2=54.00>>54.00 in overtime pay\n",
      "2 hours of overtime pay for 5 days means she makes 54*5 = $270.00\n",
      "In 5 days her base pay is $720.00 and she makes $270.00 in overtime pay so she makes $720 + $270 = $<<720+270=990.00>>990.00\n",
      "#### 990\n",
      "----------------------------------------\n",
      "\n",
      "数据集大小: 7473 条\n",
      "字段列表: question, answer\n",
      "\n",
      "总占用空间: 8.71 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from huggingface_hub import scan_cache_dir\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Hugging Face 数据集默认缓存目录\n",
    "cache_dir = os.path.expanduser('~/.cache/huggingface/datasets')\n",
    "\n",
    "def get_dataset_info():\n",
    "    if os.path.exists(cache_dir):\n",
    "        print(f\"数据集缓存目录: {cache_dir}\")\n",
    "        print(\"\\n本地数据集信息:\")\n",
    "        \n",
    "        total_size = 0\n",
    "        for dataset_dir in Path(cache_dir).rglob('dataset_info.json'):\n",
    "            try:\n",
    "                # 读取数据集信息\n",
    "                with open(dataset_dir, 'r', encoding='utf-8') as f:\n",
    "                    info = json.load(f)\n",
    "                \n",
    "                # 基础信息统计\n",
    "                dir_size = sum(f.stat().st_size for f in dataset_dir.parent.glob('**/*') if f.is_file())\n",
    "                dir_size_mb = dir_size / (1024 * 1024)\n",
    "                \n",
    "                # 提取正确的数据集名称\n",
    "                path_parts = str(dataset_dir.parent).split(os.sep)\n",
    "                dataset_name = None\n",
    "                config_name = None\n",
    "                \n",
    "                # 尝试从路径中提取数据集名称和配置名称\n",
    "                for part in path_parts:\n",
    "                    if \"___\" in part:\n",
    "                        # 从目录名称中提取数据集名称，例如 openai___gsm8k -> openai/gsm8k\n",
    "                        dataset_name = part.replace(\"___\", \"/\")\n",
    "                    # 检查是否有配置名称\n",
    "                    elif part in ['main', 'socratic'] or dataset_dir.parent.name in ['main', 'socratic']:\n",
    "                        config_name = part if part in ['main', 'socratic'] else dataset_dir.parent.name\n",
    "                \n",
    "                # 如果没有找到，使用原来的方法\n",
    "                if not dataset_name:\n",
    "                    dataset_name = dataset_dir.parent.parent.name\n",
    "                    if dataset_name == \"datasets\":\n",
    "                        dataset_name = dataset_dir.parent.parent.parent.name\n",
    "                \n",
    "                print(f\"\\n{'='*50}\")\n",
    "                print(f\"数据集: {dataset_name}\")\n",
    "                if config_name:\n",
    "                    print(f\"配置: {config_name}\")\n",
    "                print(f\"路径: {dataset_dir.parent}\")\n",
    "                print(f\"大小: {dir_size_mb:.2f} MB\")\n",
    "                \n",
    "                # 显示数据集详细信息\n",
    "                if 'description' in info:\n",
    "                    print(f\"\\n描述: {info['description'][:200]}...\")\n",
    "                if 'citation' in info:\n",
    "                    print(f\"引用: {info['citation'][:200]}...\")\n",
    "                \n",
    "                # 尝试直接加载数据集\n",
    "                try:\n",
    "                    # 使用正确的数据集名称和配置名称加载\n",
    "                    if config_name:\n",
    "                        dataset = load_dataset(dataset_name, config_name, trust_remote_code=True)\n",
    "                    else:\n",
    "                        # 尝试获取可用的配置\n",
    "                        try:\n",
    "                            configs = info.get('config_names', [])\n",
    "                            if configs:\n",
    "                                config_name = configs[0]['name']\n",
    "                                print(f\"自动选择配置: {config_name}\")\n",
    "                                dataset = load_dataset(dataset_name, config_name, trust_remote_code=True)\n",
    "                            else:\n",
    "                                dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "                        except Exception:\n",
    "                            dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "                    \n",
    "                    if dataset is not None:\n",
    "                        print(\"\\n数据样例(前10条):\")\n",
    "                        # 处理数据集可能有多个分片的情况\n",
    "                        if isinstance(dataset, dict):\n",
    "                            split_name = next(iter(dataset.keys()))  # 获取第一个分片名称\n",
    "                            df = dataset[split_name].to_pandas().head(10)\n",
    "                            \n",
    "                            # 设置显示选项\n",
    "                            pd.set_option('display.max_colwidth', None)  # 不截断列内容\n",
    "                            pd.set_option('display.width', 1000)  # 增加显示宽度\n",
    "                            \n",
    "                            # 逐行显示数据\n",
    "                            for i, (_, row) in enumerate(df.iterrows()):\n",
    "                                print(f\"\\n--- 数据 {i+1} ---\")\n",
    "                                for col, val in row.items():\n",
    "                                    print(f\"{col}: {val}\")\n",
    "                                print(\"-\" * 40)\n",
    "                            \n",
    "                            # 恢复显示选项\n",
    "                            pd.reset_option('display.max_colwidth')\n",
    "                            pd.reset_option('display.width')\n",
    "                            \n",
    "                            print(f\"\\n数据集大小: {len(dataset[split_name])} 条\")\n",
    "                            print(f\"字段列表: {', '.join(dataset[split_name].column_names)}\")\n",
    "                        else:\n",
    "                            # 同样处理非字典类型的数据集\n",
    "                            df = dataset.to_pandas().head(10)\n",
    "                            \n",
    "                            pd.set_option('display.max_colwidth', None)\n",
    "                            pd.set_option('display.width', 1000)\n",
    "                            \n",
    "                            for i, (_, row) in enumerate(df.iterrows()):\n",
    "                                print(f\"\\n--- 数据 {i+1} ---\")\n",
    "                                for col, val in row.items():\n",
    "                                    print(f\"{col}: {val}\")\n",
    "                                print(\"-\" * 40)\n",
    "                            \n",
    "                            pd.reset_option('display.max_colwidth')\n",
    "                            pd.reset_option('display.width')\n",
    "                            \n",
    "                            print(f\"\\n数据集大小: {len(dataset)} 条\")\n",
    "                            print(f\"字段列表: {', '.join(dataset.column_names)}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"加载数据集失败: {str(e)}\")\n",
    "                    # 尝试直接读取 arrow 文件\n",
    "                    try:\n",
    "                        arrow_files = list(dataset_dir.parent.glob('*.arrow'))\n",
    "                        if arrow_files:\n",
    "                            print(\"\\n尝试直接读取 arrow 文件:\")\n",
    "                            for arrow_file in arrow_files[:1]:  # 只读取第一个文件作为示例\n",
    "                                try:\n",
    "                                    # 检查文件是否为有效的Arrow文件\n",
    "                                    with open(str(arrow_file), 'rb') as f:\n",
    "                                        header = f.read(6)\n",
    "                                        if header == b'ARROW1':\n",
    "                                            print(f\"找到有效的Arrow文件: {arrow_file.name}\")\n",
    "                                            # 使用pyarrow读取\n",
    "                                            try:\n",
    "                                                with pa.memory_map(str(arrow_file), 'r') as source:\n",
    "                                                    reader = pa.ipc.open_file(source)\n",
    "                                                    table = reader.read_all()\n",
    "                                                    \n",
    "                                                    # 设置pandas显示选项\n",
    "                                                    pd.set_option('display.max_colwidth', None)\n",
    "                                                    pd.set_option('display.width', 1000)\n",
    "                                                    \n",
    "                                                    df = table.to_pandas()\n",
    "                                                    print(f\"成功读取数据，共 {len(df)} 条记录\")\n",
    "                                                    \n",
    "                                                    # 逐行显示前10条数据\n",
    "                                                    for i, (_, row) in enumerate(df.head(10).iterrows()):\n",
    "                                                        print(f\"\\n--- 数据 {i+1} ---\")\n",
    "                                                        for col, val in row.items():\n",
    "                                                            print(f\"{col}: {val}\")\n",
    "                                                        print(\"-\" * 40)\n",
    "                                                    \n",
    "                                                    # 恢复显示选项\n",
    "                                                    pd.reset_option('display.max_colwidth')\n",
    "                                                    pd.reset_option('display.width')\n",
    "                                                    \n",
    "                                                    print(f\"\\n数据集大小: {len(df)} 条\")\n",
    "                                                    print(f\"字段列表: {', '.join(df.columns)}\")\n",
    "                                            except Exception as e:\n",
    "                                                print(f\"读取Arrow文件内容失败: {str(e)}\")\n",
    "                                        else:\n",
    "                                            print(f\"文件 {arrow_file.name} 不是有效的Arrow文件\")\n",
    "                                            \n",
    "                                            # 尝试使用其他方法读取\n",
    "                                            try:\n",
    "                                                # 尝试使用parquet格式读取\n",
    "                                                df = pq.read_table(str(arrow_file)).to_pandas()\n",
    "                                                print(f\"成功以Parquet格式读取: {arrow_file.name}\")\n",
    "                                                \n",
    "                                                pd.set_option('display.max_colwidth', None)\n",
    "                                                pd.set_option('display.width', 1000)\n",
    "                                                \n",
    "                                                for i, (_, row) in enumerate(df.head(10).iterrows()):\n",
    "                                                    print(f\"\\n--- 数据 {i+1} ---\")\n",
    "                                                    for col, val in row.items():\n",
    "                                                        print(f\"{col}: {val}\")\n",
    "                                                    print(\"-\" * 40)\n",
    "                                                \n",
    "                                                pd.reset_option('display.max_colwidth')\n",
    "                                                pd.reset_option('display.width')\n",
    "                                                \n",
    "                                                print(f\"\\n数据集大小: {len(df)} 条\")\n",
    "                                                print(f\"字段列表: {', '.join(df.columns)}\")\n",
    "                                            except Exception as e:\n",
    "                                                print(f\"尝试其他格式读取失败: {str(e)}\")\n",
    "                                except Exception as e:\n",
    "                                    print(f\"读取 {arrow_file.name} 失败: {str(e)}\")\n",
    "                        else:\n",
    "                            print(\"未找到Arrow文件\")\n",
    "                            \n",
    "                            # 尝试查找其他格式的数据文件\n",
    "                            parquet_files = list(dataset_dir.parent.glob('*.parquet'))\n",
    "                            if parquet_files:\n",
    "                                print(\"\\n尝试读取Parquet文件:\")\n",
    "                                for parquet_file in parquet_files[:1]:\n",
    "                                    try:\n",
    "                                        df = pq.read_table(str(parquet_file)).to_pandas()\n",
    "                                        print(f\"成功读取Parquet文件: {parquet_file.name}\")\n",
    "                                        \n",
    "                                        pd.set_option('display.max_colwidth', None)\n",
    "                                        pd.set_option('display.width', 1000)\n",
    "                                        \n",
    "                                        for i, (_, row) in enumerate(df.head(10).iterrows()):\n",
    "                                            print(f\"\\n--- 数据 {i+1} ---\")\n",
    "                                            for col, val in row.items():\n",
    "                                                print(f\"{col}: {val}\")\n",
    "                                            print(\"-\" * 40)\n",
    "                                        \n",
    "                                        pd.reset_option('display.max_colwidth')\n",
    "                                        pd.reset_option('display.width')\n",
    "                                        \n",
    "                                        print(f\"\\n数据集大小: {len(df)} 条\")\n",
    "                                        print(f\"字段列表: {', '.join(df.columns)}\")\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"读取Parquet文件失败: {str(e)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"查找数据文件失败: {str(e)}\")\n",
    "                \n",
    "                total_size += dir_size\n",
    "            except Exception as e:\n",
    "                print(f\"处理数据集时出错: {str(e)}\")\n",
    "        \n",
    "        print(f\"\\n总占用空间: {total_size / (1024 * 1024):.2f} MB\")\n",
    "    else:\n",
    "        print(\"未找到本地数据集缓存\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_dataset_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
