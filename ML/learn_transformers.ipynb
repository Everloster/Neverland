{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ transformers åº“è¿›è¡Œæ–‡æœ¬åˆ†ç±»,åªæŒ‡å®šæ¨¡å‹åå­—ï¼Œè·å–é»˜è®¤çš„æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"ä½ å¥½å•Š\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier([\"We are very happy to show you the ğŸ¤— Transformers library.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨å¤šè¯­è¨€æ”¯æŒçš„æ¨¡å‹è¿›è¡Œåˆ†ç±»ï¼ŒæŒ‡å®šæ¨¡å‹åå­—ï¼Œè·å–æ¨¡å‹å’Œtokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# å‡†å¤‡ä¸åŒè¯­è¨€çš„æµ‹è¯•æ–‡æœ¬\n",
    "texts = [\n",
    "    (\"è‹±è¯­\", \"I am very happy to show you the ğŸ¤— Transformers library.\"),\n",
    "    (\"ä¸­æ–‡\", \"æˆ‘å¾ˆé«˜å…´èƒ½ä½¿ç”¨Transformersåº“æ¥å¤„ç†è‡ªç„¶è¯­è¨€ã€‚\"),\n",
    "    (\"æ³•è¯­\", \"Je suis trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que Transformers.\"),\n",
    "    (\"æ—¥è¯­\", \"Transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã§ãã¦æœ¬å½“ã«å¬‰ã—ã„ã§ã™ã€‚\"),\n",
    "    (\"å¾·è¯­\", \"Ich bin sehr glÃ¼cklich, Ihnen die Transformers-Bibliothek zu zeigen.\"),\n",
    "    (\"è¥¿ç­ç‰™è¯­\", \"Estoy muy feliz de mostrarles la biblioteca Transformers.\"),\n",
    "    (\"é˜¿æ‹‰ä¼¯è¯­\", \"Ø£Ù†Ø§ Ø³Ø¹ÙŠØ¯ Ø¬Ø¯Ø§ Ù„Ø£Ø¸Ù‡Ø± Ù„ÙƒÙ… Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª.\")\n",
    "]\n",
    "\n",
    "# æå–æ–‡æœ¬åˆ—è¡¨\n",
    "text_list = [text for _, text in texts]\n",
    "\n",
    "# ä½¿ç”¨tokenizerè¿›è¡Œæ‰¹é‡ç¼–ç \n",
    "pt_batch = tokenizer(text_list,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "# åˆ†ææ¯ç§è¯­è¨€çš„æ–‡æœ¬å¹¶æ‰“å°ç»“æœ\n",
    "for i, (language, text) in enumerate(texts):\n",
    "    result = classifier(text)[0]\n",
    "    print(f\"è¯­è¨€: {language}\")\n",
    "    print(f\"æ–‡æœ¬: {text}\")\n",
    "    print(f\"ç¼–ç : {pt_batch['input_ids'][i].tolist()}\")\n",
    "    print(f\"æƒ…æ„Ÿåˆ†æç»“æœ: {result['label']}\")\n",
    "    print(f\"ç½®ä¿¡åº¦: {result['score']:.4f}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ auto model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-2.5757, -2.7271, -0.9195,  1.9724,  3.2714],\n",
      "        [-1.9059, -1.8607, -0.5966,  1.1100,  2.5102],\n",
      "        [-2.3211, -2.4435, -0.5569,  1.6607,  2.8887],\n",
      "        [-2.3028, -1.7910,  0.1935,  1.5138,  1.7481],\n",
      "        [-2.2007, -2.4555, -0.9112,  1.6622,  3.0401],\n",
      "        [-2.2117, -2.4682, -0.6222,  1.7106,  2.8585],\n",
      "        [-0.7225, -0.3669,  0.4493,  0.4018,  0.1423]],\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name, torch_dtype=\"auto\")\n",
    "\n",
    "pt_outputs = pt_model(**pt_batch)\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
